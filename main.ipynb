{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "from DataGenerator import DataGenerator\n",
    "\n",
    "BATCH_SIZE=10\n",
    "IMG_SIZE=512\n",
    "export_path='model/cnn.h5'\n",
    "train_gen = DataGenerator('./TrainData', BATCH_SIZE, IMG_SIZE, aug=True)\n",
    "test_gen = DataGenerator('./TestData', BATCH_SIZE, IMG_SIZE, aug=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from BuildModel import build_model\n",
    "\n",
    "\n",
    "############## Loss function ##############\n",
    "def loss_function(y_true, y_pred):\n",
    "  squared_diff = tf.square(y_true - y_pred)\n",
    "  return tf.reduce_mean(squared_diff)\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coef(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = tf.keras.losses.binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "##########################################\n",
    "\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "#loss_function\n",
    "\n",
    "model = build_model(IMG_SIZE)\n",
    "\n",
    "# validation_split = 0.1, callbacks=[mc, rl, es]\n",
    "# model = create_model()\n",
    "# model.load_weights('/content/drive/Shareddrives/生物傳輸/data/simple_weights_8.h5')\n",
    "model.compile(optimizer=opt,loss=bce_dice_loss,metrics=[dice_coef])\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "mc = ModelCheckpoint(filepath= export_path, \n",
    "                    monitor='val_dice_coef', \n",
    "                    mode='max', \n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=False)\n",
    "rl = ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.5, patience=8)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=15)\n",
    "# tb = TensorBoard(log_dir=model_dir)\n",
    "callbacks_list = [mc, rl, es]\n",
    "\n",
    "model.fit(train_gen,\n",
    "          validation_data = test_gen,\n",
    "          batch_size=12, epochs=40,\n",
    "          validation_split = 0.1, callbacks=[mc, rl, es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "\n",
    "def tooth_predict(img_path,model_path):\n",
    "    import cv2\n",
    "    img=cv2.imread(img_path)\n",
    "    w,h,d =img.shape()\n",
    "    img=cv2.resize(img,(512,512))\n",
    "    model = load_model(model_path)\n",
    "    pred=model.predict(np.expand_dims(img,axis=0))\n",
    "    return cv2.resize(pred,(w,h))\n",
    "\n",
    "    \n",
    "\n",
    "img_path=''\n",
    "model_path='model/cnn.h5'\n",
    "cv2.imshow(tooth_predict(img_path,model_path))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
